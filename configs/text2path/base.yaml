model:
  # Pretrained encoder checkpoint (text-only conditioning).
  encoder_path: "checkpoints/base_20251217_211504/final"
  freeze_encoder: true

  # Decoder (cross-attention over [SEP] + all text hidden states)
  decoder_n_layers: 6
  decoder_n_heads: null   # default: encoder n_heads
  decoder_d_ff: null      # default: encoder d_ff
  dropout: null           # default: encoder dropout

  # Output distribution (logistic-normal in [0,1])
  out_dim: 2              # x,y
  sigma_min: 0.001
  target_eps: 0.0001      # clamp labels to (eps, 1-eps) before logit
  scheduled_sampling_ratio: 0.3
  scheduled_sampling_warmup_steps: 5000

data:
  dataset_name: "futo-org/swipe.futo.org"
  train_split: "train"
  val_split: "validation"
  path_resample_mode: "time"

  # Optional dataset slicing (set to null for full split)
  max_train_samples: null
  max_eval_samples: 10000

training:
  training_args:
    output_dir: "checkpoints/text2path"
    logging_dir: "logs/text2path"

    num_train_epochs: 10
    per_device_train_batch_size: 512
    per_device_eval_batch_size: 512
    gradient_accumulation_steps: 1

    learning_rate: 0.0001
    weight_decay: 0.01
    warmup_ratio: 0.05
    lr_scheduler_type: "cosine"
    max_grad_norm: 1.0

    logging_strategy: "steps"
    logging_steps: 10

    eval_strategy: "steps"
    eval_steps: 250

    save_strategy: "steps"
    save_steps: 250
    save_total_limit: 2
    save_safetensors: true

    remove_unused_columns: false
    report_to: ["tensorboard"]
